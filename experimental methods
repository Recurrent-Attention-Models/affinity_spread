Behavioral methods

Participants:

72 undergraduate students participated in our experiment for course credit. Their mean age was 20.4 years (range = 17–32) and all had normal or corrected-to-normal vision. This study was approved by the school Institutional Review Board. 

Stimuli and Apparatus:

We selected 288 images from the Microsoft COCO (Common Objects in Context) dataset, which has images of complex everyday scenes depicting common objects in their natural context. The images also come with object-level segmentations, which we used to generate four versions of each display: "same-close" (two dots in the same object with a close distance), "same-far" (two dots in the same object with a far distance), "different-close" (two dots in two different objects with a close distance), and "different-far" (two dots in two different objects with a far distance). We ensured that the distances are controlled for between the two same/different conditions preventing the participants to make the same/different decision based on distance. Fig.~\ref{fig:beh_exp}C shows the placement of the dots across all four conditions. The assignment of images to the four conditions was counterbalanced across participants. The experiment was conducted on a 19-inch flat-screen CRT ViewSonic SVGA monitor with a screen resolution of 1024×768 pixels and a refresh rate of 100 Hz. Participants were seated approximately 70 cm away from the monitor, which resulted in the screen subtending a visual angle of 30◦ ×22◦. This meant that around 34 image pixels spanned approximately 1 degree of visual angle. The two dots used in the experiment were located around 3 degrees from the central fixation point for the close condition and 6 degrees for the peripheral dot. Gaze position during reading was recorded using an EyeLink 1000 eye-tracking system (SR Research) with a sampling rate of 1000 Hz. Gaze coordinates were parsed into fixations using the default Eyelink algorithm, which employed a velocity threshold of 30 degrees per second and an acceleration threshold of 8000 degrees per second squared. Calibration drift was checked before every trial, and recalibration was performed if necessary to ensure accurate eye-tracking data. 

Procedure:

Participants were instructed to determine whether two dots belonged to the same object or different objects. Each trial started with the presentation of a fixation cross, which remained on the screen for 500 ms, indicating the location of the central dot. At the start of each trial, both central and peripheral cues were displayed for 1,000 ms without the image. Next the cues were superimposed and flickered at a frequency of 5 Hz to ensure their visibility. During the trial, participants were required to maintain their gaze on the screen for the entire duration. If their gaze deviated more than 1 degree of visual angle away from the first dot during this period, the trial was terminated. To record their responses, participants utilized a Microsoft gamepad controller, with buttons randomly assigned to the "same" or "different" condition. The experiment consisted of a total of 32 practice trials and 256 experimental trials. The experimental trials were divided into four blocks, with breaks provided between the blocks. The order of image presentation was randomized across the trials. To provide accuracy feedback, a sound alarm was used to indicate an incorrect response to participants. We removed one experimental image from our analyses as the ground truth response was ambiguous leavening 255 experimental images and 1020 (255*4) trials for behavioral analyses and model comparison. 



